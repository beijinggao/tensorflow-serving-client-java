<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="zh">
<head>
<!-- Generated by javadoc (1.8.0_152) on Fri Jan 04 10:31:48 CST 2019 -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>GPUOptionsOrBuilder (tensorflow-client 1.11.0 API)</title>
<meta name="date" content="2019-01-04">
<link rel="stylesheet" type="text/css" href="../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="GPUOptionsOrBuilder (tensorflow-client 1.11.0 API)";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":6,"i1":6,"i2":6,"i3":6,"i4":6,"i5":6,"i6":6,"i7":6,"i8":6,"i9":6,"i10":6,"i11":6,"i12":6};
var tabs = {65535:["t0","所有方法"],2:["t2","实例方法"],4:["t3","抽象方法"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>您的浏览器已禁用 JavaScript。</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="class-use/GPUOptionsOrBuilder.html">使用</a></li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../index-all.html">索引</a></li>
<li><a href="../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../org/tensorflow/framework/GPUOptions.ExperimentalOrBuilder.html" title="org.tensorflow.framework中的接口"><span class="typeNameLink">上一个类</span></a></li>
<li><a href="../../../org/tensorflow/framework/GradientDef.html" title="org.tensorflow.framework中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?org/tensorflow/framework/GPUOptionsOrBuilder.html" target="_top">框架</a></li>
<li><a href="GPUOptionsOrBuilder.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.tensorflow.framework</div>
<h2 title="接口 GPUOptionsOrBuilder" class="title">接口 GPUOptionsOrBuilder</h2>
</div>
<div class="contentContainer">
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>所有超级接口:</dt>
<dd>com.google.protobuf.MessageLiteOrBuilder, com.google.protobuf.MessageOrBuilder</dd>
</dl>
<dl>
<dt>所有已知实现类:</dt>
<dd><a href="../../../org/tensorflow/framework/GPUOptions.html" title="org.tensorflow.framework中的类">GPUOptions</a>, <a href="../../../org/tensorflow/framework/GPUOptions.Builder.html" title="org.tensorflow.framework中的类">GPUOptions.Builder</a></dd>
</dl>
<hr>
<br>
<pre>public interface <span class="typeNameLabel">GPUOptionsOrBuilder</span>
extends com.google.protobuf.MessageOrBuilder</pre>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>方法概要</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="方法概要表, 列表方法和解释">
<caption><span id="t0" class="activeTableTab"><span>所有方法</span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">实例方法</a></span><span class="tabEnd">&nbsp;</span></span><span id="t3" class="tableTab"><span><a href="javascript:show(4);">抽象方法</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">限定符和类型</th>
<th class="colLast" scope="col">方法和说明</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getAllocatorType--">getAllocatorType</a></span>()</code>
<div class="block">
 The type of GPU allocation strategy to use.</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>com.google.protobuf.ByteString</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getAllocatorTypeBytes--">getAllocatorTypeBytes</a></span>()</code>
<div class="block">
 The type of GPU allocation strategy to use.</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getAllowGrowth--">getAllowGrowth</a></span>()</code>
<div class="block">
 If true, the allocator does not pre-allocate the entire specified
 GPU memory region, instead starting small and growing as needed.</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getDeferredDeletionBytes--">getDeferredDeletionBytes</a></span>()</code>
<div class="block">
 Delay deletion of up to this many bytes to reduce the number of
 interactions with gpu driver code.</div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code><a href="../../../org/tensorflow/framework/GPUOptions.Experimental.html" title="org.tensorflow.framework中的类">GPUOptions.Experimental</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getExperimental--">getExperimental</a></span>()</code>
<div class="block">
 Everything inside experimental is subject to change and is not subject
 to API stability guarantees in
 https://www.tensorflow.org/guide/version_compat.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code><a href="../../../org/tensorflow/framework/GPUOptions.ExperimentalOrBuilder.html" title="org.tensorflow.framework中的接口">GPUOptions.ExperimentalOrBuilder</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getExperimentalOrBuilder--">getExperimentalOrBuilder</a></span>()</code>
<div class="block">
 Everything inside experimental is subject to change and is not subject
 to API stability guarantees in
 https://www.tensorflow.org/guide/version_compat.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getForceGpuCompatible--">getForceGpuCompatible</a></span>()</code>
<div class="block">
 Force all tensors to be gpu_compatible.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getPerProcessGpuMemoryFraction--">getPerProcessGpuMemoryFraction</a></span>()</code>
<div class="block">
 Fraction of the available GPU memory to allocate for each process.
 1 means to allocate all of the GPU memory, 0.5 means the process
 allocates up to ~50% of the available GPU memory.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getPollingActiveDelayUsecs--">getPollingActiveDelayUsecs</a></span>()</code>
<div class="block">
 In the event polling loop sleep this many microseconds between
 PollEvents calls, when the queue is not empty.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getPollingInactiveDelayMsecs--">getPollingInactiveDelayMsecs</a></span>()</code>
<div class="block">
 This field is deprecated and ignored.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getVisibleDeviceList--">getVisibleDeviceList</a></span>()</code>
<div class="block">
 A comma-separated list of GPU ids that determines the 'visible'
 to 'virtual' mapping of GPU devices.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>com.google.protobuf.ByteString</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#getVisibleDeviceListBytes--">getVisibleDeviceListBytes</a></span>()</code>
<div class="block">
 A comma-separated list of GPU ids that determines the 'visible'
 to 'virtual' mapping of GPU devices.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../org/tensorflow/framework/GPUOptionsOrBuilder.html#hasExperimental--">hasExperimental</a></span>()</code>
<div class="block">
 Everything inside experimental is subject to change and is not subject
 to API stability guarantees in
 https://www.tensorflow.org/guide/version_compat.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.com.google.protobuf.MessageOrBuilder">
<!--   -->
</a>
<h3>从接口继承的方法&nbsp;com.google.protobuf.MessageOrBuilder</h3>
<code>findInitializationErrors, getAllFields, getDefaultInstanceForType, getDescriptorForType, getField, getInitializationErrorString, getOneofFieldDescriptor, getRepeatedField, getRepeatedFieldCount, getUnknownFields, hasField, hasOneof</code></li>
</ul>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.com.google.protobuf.MessageLiteOrBuilder">
<!--   -->
</a>
<h3>从接口继承的方法&nbsp;com.google.protobuf.MessageLiteOrBuilder</h3>
<code>isInitialized</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>方法详细资料</h3>
<a name="getPerProcessGpuMemoryFraction--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPerProcessGpuMemoryFraction</h4>
<pre>double&nbsp;getPerProcessGpuMemoryFraction()</pre>
<div class="block"><pre>
 Fraction of the available GPU memory to allocate for each process.
 1 means to allocate all of the GPU memory, 0.5 means the process
 allocates up to ~50% of the available GPU memory.
 GPU memory is pre-allocated unless the allow_growth option is enabled.
 If greater than 1.0, uses CUDA unified memory to potentially oversubscribe
 the amount of memory available on the GPU device by using host memory as a
 swap space. Accessing memory not available on the device will be
 significantly slower as that would require memory transfer between the host
 and the device. Options to reduce the memory requirement should be
 considered before enabling this option as this may come with a negative
 performance impact. Oversubscription using the unified memory requires
 Pascal class or newer GPUs and it is currently only supported on the Linux
 operating system. See
 https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements
 for the detailed requirements.
 </pre>

 <code>double per_process_gpu_memory_fraction = 1;</code></div>
</li>
</ul>
<a name="getAllowGrowth--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllowGrowth</h4>
<pre>boolean&nbsp;getAllowGrowth()</pre>
<div class="block"><pre>
 If true, the allocator does not pre-allocate the entire specified
 GPU memory region, instead starting small and growing as needed.
 </pre>

 <code>bool allow_growth = 4;</code></div>
</li>
</ul>
<a name="getAllocatorType--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllocatorType</h4>
<pre>java.lang.String&nbsp;getAllocatorType()</pre>
<div class="block"><pre>
 The type of GPU allocation strategy to use.
 Allowed values:
 "": The empty string (default) uses a system-chosen default
     which may change over time.
 "BFC": A "Best-fit with coalescing" algorithm, simplified from a
        version of dlmalloc.
 </pre>

 <code>string allocator_type = 2;</code></div>
</li>
</ul>
<a name="getAllocatorTypeBytes--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getAllocatorTypeBytes</h4>
<pre>com.google.protobuf.ByteString&nbsp;getAllocatorTypeBytes()</pre>
<div class="block"><pre>
 The type of GPU allocation strategy to use.
 Allowed values:
 "": The empty string (default) uses a system-chosen default
     which may change over time.
 "BFC": A "Best-fit with coalescing" algorithm, simplified from a
        version of dlmalloc.
 </pre>

 <code>string allocator_type = 2;</code></div>
</li>
</ul>
<a name="getDeferredDeletionBytes--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDeferredDeletionBytes</h4>
<pre>long&nbsp;getDeferredDeletionBytes()</pre>
<div class="block"><pre>
 Delay deletion of up to this many bytes to reduce the number of
 interactions with gpu driver code.  If 0, the system chooses
 a reasonable default (several MBs).
 </pre>

 <code>int64 deferred_deletion_bytes = 3;</code></div>
</li>
</ul>
<a name="getVisibleDeviceList--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getVisibleDeviceList</h4>
<pre>java.lang.String&nbsp;getVisibleDeviceList()</pre>
<div class="block"><pre>
 A comma-separated list of GPU ids that determines the 'visible'
 to 'virtual' mapping of GPU devices.  For example, if TensorFlow
 can see 8 GPU devices in the process, and one wanted to map
 visible GPU devices 5 and 3 as "/device:GPU:0", and "/device:GPU:1",
 then one would specify this field as "5,3".  This field is similar in
 spirit to the CUDA_VISIBLE_DEVICES environment variable, except
 it applies to the visible GPU devices in the process.
 NOTE:
 1. The GPU driver provides the process with the visible GPUs
    in an order which is not guaranteed to have any correlation to
    the *physical* GPU id in the machine.  This field is used for
    remapping "visible" to "virtual", which means this operates only
    after the process starts.  Users are required to use vendor
    specific mechanisms (e.g., CUDA_VISIBLE_DEVICES) to control the
    physical to visible device mapping prior to invoking TensorFlow.
 2. In the code, the ids in this list are also called "CUDA GPU id"s,
    and the 'virtual' ids of GPU devices (i.e. the ids in the device
    name "/device:GPU:&lt;id&gt;") are also called "TF GPU id"s. Please
    refer to third_party/tensorflow/core/common_runtime/gpu/gpu_id.h
    for more information.
 </pre>

 <code>string visible_device_list = 5;</code></div>
</li>
</ul>
<a name="getVisibleDeviceListBytes--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getVisibleDeviceListBytes</h4>
<pre>com.google.protobuf.ByteString&nbsp;getVisibleDeviceListBytes()</pre>
<div class="block"><pre>
 A comma-separated list of GPU ids that determines the 'visible'
 to 'virtual' mapping of GPU devices.  For example, if TensorFlow
 can see 8 GPU devices in the process, and one wanted to map
 visible GPU devices 5 and 3 as "/device:GPU:0", and "/device:GPU:1",
 then one would specify this field as "5,3".  This field is similar in
 spirit to the CUDA_VISIBLE_DEVICES environment variable, except
 it applies to the visible GPU devices in the process.
 NOTE:
 1. The GPU driver provides the process with the visible GPUs
    in an order which is not guaranteed to have any correlation to
    the *physical* GPU id in the machine.  This field is used for
    remapping "visible" to "virtual", which means this operates only
    after the process starts.  Users are required to use vendor
    specific mechanisms (e.g., CUDA_VISIBLE_DEVICES) to control the
    physical to visible device mapping prior to invoking TensorFlow.
 2. In the code, the ids in this list are also called "CUDA GPU id"s,
    and the 'virtual' ids of GPU devices (i.e. the ids in the device
    name "/device:GPU:&lt;id&gt;") are also called "TF GPU id"s. Please
    refer to third_party/tensorflow/core/common_runtime/gpu/gpu_id.h
    for more information.
 </pre>

 <code>string visible_device_list = 5;</code></div>
</li>
</ul>
<a name="getPollingActiveDelayUsecs--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPollingActiveDelayUsecs</h4>
<pre>int&nbsp;getPollingActiveDelayUsecs()</pre>
<div class="block"><pre>
 In the event polling loop sleep this many microseconds between
 PollEvents calls, when the queue is not empty.  If value is not
 set or set to 0, gets set to a non-zero default.
 </pre>

 <code>int32 polling_active_delay_usecs = 6;</code></div>
</li>
</ul>
<a name="getPollingInactiveDelayMsecs--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getPollingInactiveDelayMsecs</h4>
<pre>int&nbsp;getPollingInactiveDelayMsecs()</pre>
<div class="block"><pre>
 This field is deprecated and ignored.
 </pre>

 <code>int32 polling_inactive_delay_msecs = 7;</code></div>
</li>
</ul>
<a name="getForceGpuCompatible--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getForceGpuCompatible</h4>
<pre>boolean&nbsp;getForceGpuCompatible()</pre>
<div class="block"><pre>
 Force all tensors to be gpu_compatible. On a GPU-enabled TensorFlow,
 enabling this option forces all CPU tensors to be allocated with Cuda
 pinned memory. Normally, TensorFlow will infer which tensors should be
 allocated as the pinned memory. But in case where the inference is
 incomplete, this option can significantly speed up the cross-device memory
 copy performance as long as it fits the memory.
 Note that this option is not something that should be
 enabled by default for unknown or very large models, since all Cuda pinned
 memory is unpageable, having too much pinned memory might negatively impact
 the overall host system performance.
 </pre>

 <code>bool force_gpu_compatible = 8;</code></div>
</li>
</ul>
<a name="hasExperimental--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hasExperimental</h4>
<pre>boolean&nbsp;hasExperimental()</pre>
<div class="block"><pre>
 Everything inside experimental is subject to change and is not subject
 to API stability guarantees in
 https://www.tensorflow.org/guide/version_compat.
 </pre>

 <code>.tensorflow.GPUOptions.Experimental experimental = 9;</code></div>
</li>
</ul>
<a name="getExperimental--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getExperimental</h4>
<pre><a href="../../../org/tensorflow/framework/GPUOptions.Experimental.html" title="org.tensorflow.framework中的类">GPUOptions.Experimental</a>&nbsp;getExperimental()</pre>
<div class="block"><pre>
 Everything inside experimental is subject to change and is not subject
 to API stability guarantees in
 https://www.tensorflow.org/guide/version_compat.
 </pre>

 <code>.tensorflow.GPUOptions.Experimental experimental = 9;</code></div>
</li>
</ul>
<a name="getExperimentalOrBuilder--">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>getExperimentalOrBuilder</h4>
<pre><a href="../../../org/tensorflow/framework/GPUOptions.ExperimentalOrBuilder.html" title="org.tensorflow.framework中的接口">GPUOptions.ExperimentalOrBuilder</a>&nbsp;getExperimentalOrBuilder()</pre>
<div class="block"><pre>
 Everything inside experimental is subject to change and is not subject
 to API stability guarantees in
 https://www.tensorflow.org/guide/version_compat.
 </pre>

 <code>.tensorflow.GPUOptions.Experimental experimental = 9;</code></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="跳过导航链接">跳过导航链接</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="导航">
<li><a href="../../../overview-summary.html">概览</a></li>
<li><a href="package-summary.html">程序包</a></li>
<li class="navBarCell1Rev">类</li>
<li><a href="class-use/GPUOptionsOrBuilder.html">使用</a></li>
<li><a href="package-tree.html">树</a></li>
<li><a href="../../../deprecated-list.html">已过时</a></li>
<li><a href="../../../index-all.html">索引</a></li>
<li><a href="../../../help-doc.html">帮助</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li><a href="../../../org/tensorflow/framework/GPUOptions.ExperimentalOrBuilder.html" title="org.tensorflow.framework中的接口"><span class="typeNameLink">上一个类</span></a></li>
<li><a href="../../../org/tensorflow/framework/GradientDef.html" title="org.tensorflow.framework中的类"><span class="typeNameLink">下一个类</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?org/tensorflow/framework/GPUOptionsOrBuilder.html" target="_top">框架</a></li>
<li><a href="GPUOptionsOrBuilder.html" target="_top">无框架</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../allclasses-noframe.html">所有类</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>概要:&nbsp;</li>
<li>嵌套&nbsp;|&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.summary">方法</a></li>
</ul>
<ul class="subNavList">
<li>详细资料:&nbsp;</li>
<li>字段&nbsp;|&nbsp;</li>
<li>构造器&nbsp;|&nbsp;</li>
<li><a href="#method.detail">方法</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<p class="legalCopy"><small>Copyright &#169; 2019. All rights reserved.</small></p>
</body>
</html>
